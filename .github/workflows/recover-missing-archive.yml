name: Recover Missing Archive

on:
  workflow_dispatch:
    inputs:
      date:
        description: 'Date of missing archive (YYYY-MM-DD)'
        required: true
        default: '2025-09-21'
      workflow_run_id:
        description: 'Workflow run ID to recover from (optional, use "latest" for most recent)'
        required: false
        default: 'latest'

jobs:
  recover:
    runs-on: self-hosted
    steps:
      - name: Install GitHub CLI if missing
        run: |
          if ! command -v gh &> /dev/null; then
            echo "GitHub CLI not found, installing..."
            curl -fsSL https://cli.github.com/packages/githubcli-archive-keyring.gpg | sudo dd of=/usr/share/keyrings/githubcli-archive-keyring.gpg
            echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main" | sudo tee /etc/apt/sources.list.d/github-cli.list > /dev/null
            sudo apt update
            sudo apt install gh -y
          else
            echo "GitHub CLI is already installed"
          fi
          
      - name: Checkout main branch
        uses: actions/checkout@v5
        with:
          ref: main
          
      - name: Checkout gh-pages branch
        uses: actions/checkout@v5
        with:
          ref: gh-pages
          path: gh-pages
          
      - name: Download artifacts using Actions API
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          DATE="${{ github.event.inputs.date }}"
          WORKFLOW_RUN_ID="${{ github.event.inputs.workflow_run_id }}"
          
          echo "Attempting to recover data for date: $DATE"
          
          # First check if data already exists in gh-pages
          if [ -d "gh-pages/accessibility-reports/$DATE" ] && [ "$(ls -A gh-pages/accessibility-reports/$DATE 2>/dev/null)" ]; then
            echo "Found existing source data directory in gh-pages with files"
            ls -la "gh-pages/accessibility-reports/$DATE/" | head -10
          else
            echo "No source data found in gh-pages for $DATE, will recover from artifacts"
            
            # If gh CLI is available, use it. Otherwise, use curl with GitHub API
            if command -v gh &> /dev/null; then
              echo "Using GitHub CLI to download artifacts..."
              
              if [ "$WORKFLOW_RUN_ID" == "latest" ] || [ -z "$WORKFLOW_RUN_ID" ]; then
                echo "Finding latest workflow run..."
                # Find the most recent run
                WORKFLOW_RUN_ID=$(gh api repos/${{ github.repository }}/actions/runs --jq '.workflow_runs[0].id')
                echo "Using latest run: $WORKFLOW_RUN_ID"
              fi
              
              # Download artifacts
              gh run download "$WORKFLOW_RUN_ID" -D temp-artifacts || {
                echo "Failed to download artifacts with gh CLI"
                echo "Available recent runs:"
                gh run list --limit 5
                exit 1
              }
            else
              echo "GitHub CLI not available, using curl to download artifacts..."
              
              # Use GitHub API directly with curl
              if [ "$WORKFLOW_RUN_ID" == "latest" ] || [ -z "$WORKFLOW_RUN_ID" ]; then
                echo "Finding latest workflow run using API..."
                WORKFLOW_RUN_ID=$(curl -s -H "Authorization: token ${{ github.token }}" \
                  "https://api.github.com/repos/${{ github.repository }}/actions/runs?per_page=1" | \
                  grep -o '"id":[0-9]*' | head -1 | cut -d: -f2)
                echo "Using latest run: $WORKFLOW_RUN_ID"
              fi
              
              # Get artifact list
              mkdir -p temp-artifacts
              echo "Getting artifacts list for run $WORKFLOW_RUN_ID..."
              
              ARTIFACTS_JSON=$(curl -s -H "Authorization: token ${{ github.token }}" \
                "https://api.github.com/repos/${{ github.repository }}/actions/runs/$WORKFLOW_RUN_ID/artifacts")
              
              # Download each artifact
              echo "$ARTIFACTS_JSON" | grep -o '"archive_download_url":"[^"]*"' | cut -d'"' -f4 | while read -r url; do
                if [ -n "$url" ]; then
                  ARTIFACT_NAME=$(echo "$ARTIFACTS_JSON" | grep -B2 "$url" | grep '"name"' | cut -d'"' -f4)
                  echo "Downloading artifact: $ARTIFACT_NAME"
                  
                  curl -L -H "Authorization: token ${{ github.token }}" \
                    -o "temp-artifacts/${ARTIFACT_NAME}.zip" "$url"
                  
                  # Extract the artifact
                  cd temp-artifacts
                  unzip -q "${ARTIFACT_NAME}.zip" -d "$ARTIFACT_NAME" || true
                  rm "${ARTIFACT_NAME}.zip"
                  cd ..
                fi
              done
            fi
            
            # Create directories
            mkdir -p "gh-pages/accessibility-reports/$DATE"
            mkdir -p "gh-pages/accessibility-reports/summaries/$DATE"
            
            # Find and copy files from artifacts
            echo "Searching for violation files in artifacts..."
            find temp-artifacts -type f -name "violations-*.json" 2>/dev/null | while read -r file; do
              cp "$file" "gh-pages/accessibility-reports/$DATE/" 2>/dev/null && \
                echo "Recovered: $(basename "$file")"
            done
            
            echo "Searching for summary files in artifacts..."
            find temp-artifacts -type f \( -name "daily_summary*.json" -o -path "*/summaries/*" \) 2>/dev/null | while read -r file; do
              cp "$file" "gh-pages/accessibility-reports/summaries/$DATE/" 2>/dev/null && \
                echo "Recovered summary: $(basename "$file")"
            done
            
            # Clean up
            rm -rf temp-artifacts
          fi
          
      - name: Create or Recreate Archive
        run: |
          DATE="${{ github.event.inputs.date }}"
          cd gh-pages
          
          # Check if we have data
          if [ ! -d "accessibility-reports/$DATE" ]; then
            echo "Creating directory: accessibility-reports/$DATE"
            mkdir -p "accessibility-reports/$DATE"
          fi
          
          # Count files
          VIOLATION_COUNT=$(find "accessibility-reports/$DATE" -name "violations-*.json" 2>/dev/null | wc -l)
          SUMMARY_COUNT=$(find "accessibility-reports/summaries/$DATE" -name "*.json" 2>/dev/null | wc -l)
          
          echo "Found $VIOLATION_COUNT violation files and $SUMMARY_COUNT summary files"
          
          # If no files found, create a placeholder
          if [ "$VIOLATION_COUNT" -eq 0 ] && [ "$SUMMARY_COUNT" -eq 0 ]; then
            echo "WARNING: No data files found, creating placeholder"
            echo "{
              \"date\": \"$DATE\",
              \"status\": \"no_data_recovered\",
              \"message\": \"No test data could be recovered for this date\",
              \"timestamp\": \"$(date -Iseconds)\"
            }" > "accessibility-reports/$DATE/placeholder.json"
            VIOLATION_COUNT=1
          fi
          
          # Create temp directory for archive
          TEMP_DIR="temp_recovery_$DATE"
          mkdir -p "$TEMP_DIR"
          
          # Copy all JSON files
          if [ -d "accessibility-reports/$DATE" ]; then
            find "accessibility-reports/$DATE" -name "*.json" -exec cp {} "$TEMP_DIR/" \; 2>/dev/null
          fi
          
          if [ -d "accessibility-reports/summaries/$DATE" ]; then
            find "accessibility-reports/summaries/$DATE" -name "*.json" -exec cp {} "$TEMP_DIR/" \; 2>/dev/null
          fi
          
          # Count total files for archive
          TOTAL_FILES=$(find "$TEMP_DIR" -name "*.json" | wc -l)
          echo "Total files to archive: $TOTAL_FILES"
          
          # Create archive directory
          mkdir -p "accessibility-reports/archives"
          
          if [ "$TOTAL_FILES" -gt 0 ]; then
            # Create archive
            cd "$TEMP_DIR"
            tar -czf "../accessibility-reports/archives/reports_$DATE.tar.gz" *.json
            cd ..
            
            # Create manifest
            tar -tzf "accessibility-reports/archives/reports_$DATE.tar.gz" | sort > "accessibility-reports/archives/reports_$DATE.manifest"
            
            # Verify
            ARCHIVE_SIZE=$(du -h "accessibility-reports/archives/reports_$DATE.tar.gz" | cut -f1)
            echo "✅ Created archive: reports_$DATE.tar.gz (Size: $ARCHIVE_SIZE)"
            ls -la "accessibility-reports/archives/reports_$DATE"*
          else
            echo "ERROR: No files to archive after recovery attempt"
            exit 1
          fi
          
          # Cleanup
          rm -rf "$TEMP_DIR"
          
      - name: Update Archive Index
        run: |
          cd gh-pages/accessibility-reports/archives
          
          # Check if we have any archives
          if ! ls *.tar.gz &>/dev/null; then
            echo "No archives found, creating empty index"
            echo "[]" > archive_index.json
            exit 0
          fi
          
          # Regenerate archive index
          echo "Regenerating archive index..."
          
          # Use a more portable approach
          > archive_index_temp.json
          echo "[" >> archive_index_temp.json
          
          FIRST=true
          for archive in reports_*.tar.gz; do
            if [ -f "$archive" ]; then
              DATE=$(echo "$archive" | grep -oE '[0-9]{4}-[0-9]{2}-[0-9]{2}')
              SIZE=$(stat -c%s "$archive" 2>/dev/null || stat -f%z "$archive" 2>/dev/null || echo "0")
              FILE_COUNT=$(wc -l < "reports_$DATE.manifest" 2>/dev/null || echo "0")
              
              if [ "$FIRST" = true ]; then
                FIRST=false
              else
                echo "," >> archive_index_temp.json
              fi
              
              echo "  {\"date\":\"$DATE\",\"filename\":\"$archive\",\"size\":\"$SIZE\",\"fileCount\":$FILE_COUNT}" >> archive_index_temp.json
            fi
          done
          
          echo "]" >> archive_index_temp.json
          
          # Sort by date if jq is available, otherwise use as-is
          if command -v jq &>/dev/null; then
            cat archive_index_temp.json | jq 'sort_by(.date) | reverse' > archive_index.json
            rm archive_index_temp.json
          else
            mv archive_index_temp.json archive_index.json
          fi
          
          echo "Archive index updated:"
          cat archive_index.json
          
      - name: Commit and Push
        run: |
          DATE="${{ github.event.inputs.date }}"
          cd gh-pages
          
          git config user.name "GitHub Actions"
          git config user.email "actions@github.com"
          
          # Add all relevant files
          git add -A "accessibility-reports/$DATE" 2>/dev/null || true
          git add -A "accessibility-reports/summaries/$DATE" 2>/dev/null || true
          git add "accessibility-reports/archives/reports_$DATE.tar.gz" 2>/dev/null || true
          git add "accessibility-reports/archives/reports_$DATE.manifest" 2>/dev/null || true
          git add "accessibility-reports/archives/archive_index.json" 2>/dev/null || true
          
          echo "Files staged for commit:"
          git status --short
          
          # Commit and push
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "Recover archive and data for $DATE [skip ci]"
            git push origin gh-pages
            echo "✅ Successfully pushed recovery to gh-pages"
          fi
          
      - name: Verify Recovery
        run: |
          DATE="${{ github.event.inputs.date }}"
          sleep 5
          
          # Simple verification using git
          cd gh-pages
          git fetch origin gh-pages
          git reset --hard origin/gh-pages
          
          if [ -f "accessibility-reports/archives/reports_${DATE}.tar.gz" ]; then
            SIZE=$(stat -c%s "accessibility-reports/archives/reports_${DATE}.tar.gz" 2>/dev/null || stat -f%z "accessibility-reports/archives/reports_${DATE}.tar.gz" 2>/dev/null)
            echo "✅ Archive successfully recovered: reports_${DATE}.tar.gz (Size: $SIZE bytes)"
            
            # Check data directory
            if [ -d "accessibility-reports/${DATE}" ]; then
              FILE_COUNT=$(find "accessibility-reports/${DATE}" -name "*.json" | wc -l)
              echo "✅ Data directory recovered with $FILE_COUNT files"
            fi
          else
            echo "❌ Archive recovery verification failed"
            ls -la accessibility-reports/archives/ | grep "$DATE" || echo "No archive for $DATE found"
            exit 1
          fi